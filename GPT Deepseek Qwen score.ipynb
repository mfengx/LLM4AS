{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f10470-1c18-4700-8d64-9408fdcc0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dfc8bf-c34a-4335-b894-b65322cc611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_number(s):\n",
    "    \"\"\"\n",
    "    Extracts the first integer from a string, ignoring decimals.\n",
    "\n",
    "    Args:\n",
    "        s: The input string.\n",
    "\n",
    "    Returns:\n",
    "        The first integer found in the string, or None if no integer is found.\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', s)  # Matches only integers\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "## Find modes ###\n",
    "def find_mode(data):\n",
    "    \"\"\"\n",
    "    Finds the mode(s) of a list or pandas Series.\n",
    "    \n",
    "    Args:\n",
    "        data: A list or pandas Series of values.\n",
    "    \n",
    "    Returns:\n",
    "        A single mode if there are multiple modes;\n",
    "        otherwise returns the mode(s) of the input data.\n",
    "        Returns an empty list if the input is empty.\n",
    "    \"\"\"\n",
    "    counts = Counter(data)\n",
    "    max_count = max(counts.values())\n",
    "    modes = [key for key, value in counts.items() if value == max_count]\n",
    "    \n",
    "    # If there are multiple modes, choose one randomly\n",
    "    if len(modes) > 1:\n",
    "        return random.choice(modes)\n",
    "    \n",
    "    return modes[0]\n",
    "\n",
    "def SMD(truevalues,prediction):\n",
    "    mt=truevalues.mean()\n",
    "    mp=prediction.mean()\n",
    "    stdt=truevalues.var()\n",
    "    stdp=prediction.var()\n",
    "    z= (mt-mp)/math.sqrt((stdt+stdt)/2)\n",
    "\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0566bf46-cc32-42ac-8e6c-51ca056837c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingf\\AppData\\Local\\Temp\\ipykernel_37388\\1477485427.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  resp.replace({'Final': {'0b': 0}},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/mingf/Documents/bokeli/semester 8/AS_Multiple LLM/'\n",
    "role = \"You are a helpful rater in science education. You should rate students' responses based on the scoring guide and only return the scores.\\n\"\n",
    "\n",
    "item='VR1'\n",
    "scoring_prompt = pd.read_csv(path+'scoring prompts.csv')\n",
    "scoring_prompt = scoring_prompt.loc[scoring_prompt.Item == item,'Prompt'].values[0]\n",
    "resp = pd.read_excel(path+'All Graded Data from LPS3 2022_ Undergraduates.xlsx',sheet_name=item)\n",
    "resp.replace({'Final': {'0a': 0}},inplace=True)\n",
    "resp.replace({'Final': {'0b': 0}},inplace=True)\n",
    "resp['Final']=resp['Final'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d18b972-6252-4ff9-82b8-e591a89ca385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingf\\AppData\\Local\\Temp\\ipykernel_26432\\3494182750.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  resp.iloc[:, 2] = resp.iloc[:, 2].replace('0b', 0)\n",
      "C:\\Users\\mingf\\AppData\\Local\\Temp\\ipykernel_26432\\3494182750.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  resp.iloc[:, 3] = resp.iloc[:, 3].replace('0b', 0)\n"
     ]
    }
   ],
   "source": [
    "resp.iloc[:, 2] = resp.iloc[:, 2].replace('0a', 0)\n",
    "resp.iloc[:, 2] = resp.iloc[:, 2].replace('0b', 0)\n",
    "resp.iloc[:, 3] = resp.iloc[:, 3].replace('0a', 0)\n",
    "resp.iloc[:, 3] = resp.iloc[:, 3].replace('0b', 0)\n",
    "\n",
    "resp['H2HA'] = (resp.iloc[:,2] == resp.iloc[:,3]).astype(float)\n",
    "resp.loc[resp.iloc[:,2].isna(),'H2HA'] = np.nan\n",
    "resp.loc[resp.iloc[:,3].isna(),'H2HA'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7f5ea8e-db93-4c68-9e11-6b34c3615fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpt_client = OpenAI(api_key='Input your own key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f1b49de-8988-4d94-966c-f7e9ea88d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprs = [0,1]\n",
    "nrep=5\n",
    "\n",
    "\n",
    "for tempr in temprs:\n",
    "    scP = []\n",
    "    for index, row in resp.iterrows():\n",
    "    #print(index)\n",
    "        scoring_prompt_resp = scoring_prompt+'\\n'+'RESPONSE:'+str(row[item])+'. ->'\n",
    "        scL=[]\n",
    "        for rp in range(nrep):\n",
    "        \n",
    "            gpt_scores = gpt_client.chat.completions.create(\n",
    "                              model=\"gpt-4o-2024-11-20\",\n",
    "                              temperature=tempr,\n",
    "                              n=1,\n",
    "                              messages=[\n",
    "                                {\"role\": \"system\", \"content\": role},\n",
    "                                {\"role\": \"user\", \"content\": scoring_prompt_resp}\n",
    "                              ])\n",
    "            scL.append(gpt_scores.choices[0].message.content)\n",
    "\n",
    "        scP.append(scL)\n",
    "\n",
    "    gpt_scD = pd.DataFrame(scP,columns=['output_'+str(i )for i in range(nrep)])\n",
    "\n",
    "    gpt_scD = pd.concat([gpt_scD,gpt_scD.apply(lambda col: [extract_first_number(i) for i in col]).\\\n",
    "    rename(columns=dict(zip(['output_'+str(i )for i in range(nrep)],['score_'+str(i )for i in range(nrep)])))], axis=1)\n",
    "\n",
    "    gpt_scD['mode'] = gpt_scD.iloc[:,nrep:(2*nrep)].apply(find_mode,axis=1)\n",
    "\n",
    "    gpt_scD.to_csv(path+'results/'+item+'_GPT_tempr'+str(tempr)+'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4784aa36-b08a-4aff-89a5-eb352fb77dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK: 0.6437145763697137\n",
      "Accuracy: 0.5837004405286343\n",
      "rmse: 0.6897614987154126\n",
      "SMD: 0.4711002503544767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75        97\n",
      "           1       0.69      0.33      0.45       212\n",
      "           2       0.47      0.94      0.63       135\n",
      "           3       0.38      0.50      0.43        10\n",
      "\n",
      "    accuracy                           0.58       454\n",
      "   macro avg       0.61      0.61      0.57       454\n",
      "weighted avg       0.66      0.58      0.57       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"QWK: {cohen_kappa_score(gpt_scD['mode'],resp.Final,weights='quadratic')}\")\n",
    "print(f\"Accuracy: {accuracy_score(gpt_scD['mode'],resp.Final)}\")\n",
    "print(f\"rmse: {root_mean_squared_error(gpt_scD['mode'],resp.Final)}\")\n",
    "print(f\"SMD: {SMD(prediction=gpt_scD['mode'],truevalues=resp.Final)}\")\n",
    "print(classification_report(gpt_scD['mode'],resp.Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8113a974-fbed-4a72-baf3-fc4b9e3e1fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_client = OpenAI(api_key=\"Input your own key\", base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62e59936-5307-4256-87a4-577ef67a9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprs = [0,1]\n",
    "nrep=5\n",
    "\n",
    "\n",
    "for tempr in temprs:\n",
    "    scP = []\n",
    "    for index, row in resp.iterrows():\n",
    "    #print(index)\n",
    "        scoring_prompt_resp = scoring_prompt+'\\n'+'RESPONSE:'+str(row[item])+'. ->'\n",
    "        scL=[]\n",
    "        for rp in range(nrep):\n",
    "        \n",
    "            ds_scores = ds_client.chat.completions.create(\n",
    "                              model=\"deepseek-chat\",\n",
    "                              temperature=tempr,\n",
    "                              n=1,\n",
    "                              messages=[\n",
    "                                {\"role\": \"system\", \"content\": role},\n",
    "                                {\"role\": \"user\", \"content\": scoring_prompt_resp}\n",
    "                              ])\n",
    "            scL.append(ds_scores.choices[0].message.content)\n",
    "\n",
    "        scP.append(scL)\n",
    "\n",
    "    ds_scD = pd.DataFrame(scP,columns=['output_'+str(i )for i in range(nrep)])\n",
    "\n",
    "    ds_scD = pd.concat([ds_scD,ds_scD.apply(lambda col: [extract_first_number(i) for i in col]).\\\n",
    "    rename(columns=dict(zip(['output_'+str(i )for i in range(nrep)],['score_'+str(i )for i in range(nrep)])))], axis=1)\n",
    "\n",
    "    ds_scD['mode'] = ds_scD.iloc[:,nrep:(2*nrep)].apply(find_mode,axis=1)\n",
    "\n",
    "    ds_scD.to_csv(path+'results/'+item+'_deepseek_tempr'+str(tempr)+'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0240fe91-f0b2-4cb5-9e8c-3033063e42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw_client = OpenAI(\n",
    "    api_key=\"Input your own key\", \n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc88dfc-e623-405c-88f5-7ef917739419",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprs = [0,1]\n",
    "nrep=5\n",
    "\n",
    "\n",
    "for tempr in temprs:\n",
    "    scP = []\n",
    "    for index, row in resp.iterrows():\n",
    "    #print(index)\n",
    "        scoring_prompt_resp = scoring_prompt+'\\n'+'RESPONSE:'+str(row[item])+'. ->'\n",
    "        scL=[]\n",
    "        for rp in range(nrep):\n",
    "        \n",
    "            qw_scores = qw_client.chat.completions.create(\n",
    "                              model=\"qwen-plus\",\n",
    "                              temperature=tempr,\n",
    "                              n=1,\n",
    "                              messages=[\n",
    "                                {\"role\": \"system\", \"content\": role},\n",
    "                                {\"role\": \"user\", \"content\": scoring_prompt_resp}\n",
    "                              ])\n",
    "            scL.append(qw_scores.choices[0].message.content)\n",
    "\n",
    "        scP.append(scL)\n",
    "\n",
    "    qw_scD = pd.DataFrame(scP,columns=['output_'+str(i )for i in range(nrep)])\n",
    "\n",
    "    qw_scD = pd.concat([qw_scD,qw_scD.apply(lambda col: [extract_first_number(i) for i in col]).\\\n",
    "    rename(columns=dict(zip(['output_'+str(i )for i in range(nrep)],['score_'+str(i )for i in range(nrep)])))], axis=1)\n",
    "\n",
    "    qw_scD['mode'] = qw_scD.iloc[:,nrep:(2*nrep)].apply(find_mode,axis=1)\n",
    "\n",
    "    qw_scD.to_csv(path+'results/'+item+'_qwen_tempr'+str(tempr)+'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fae58bff-96d5-483d-9872-bc82d19d2a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK: 0.4425231296739678\n",
      "Accuracy: 0.4043478260869565\n",
      "rmse: 0.8444190181781018\n",
      "SMD: 0.6327597196944021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        54\n",
      "           1       0.84      0.33      0.47       330\n",
      "           2       0.19      0.55      0.28        76\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40       460\n",
      "   macro avg       0.41      0.38      0.35       460\n",
      "weighted avg       0.71      0.40      0.46       460\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingf\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mingf\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mingf\\anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(f\"QWK: {cohen_kappa_score(qw_scD['mode'],resp.Final,weights='quadratic')}\")\n",
    "print(f\"Accuracy: {accuracy_score(qw_scD['mode'],resp.Final)}\")\n",
    "print(f\"rmse: {root_mean_squared_error(qw_scD['mode'],resp.Final)}\")\n",
    "print(f\"SMD: {SMD(prediction=qw_scD['mode'],truevalues=resp.Final)}\")\n",
    "print(classification_report(qw_scD['mode'],resp.Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78dcfcc3-56bd-401b-81c7-f666cfa42459",
   "metadata": {},
   "outputs": [],
   "source": [
    "qw_scD_1 = pd.DataFrame({'output': [i[0] for i in scP],'prediction':[extract_first_number(i[0]) for i in scP],'tlabel':resp.Final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f46d167-54df-4865-864c-7394fbb465f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK: 0.7985629648304551\n",
      "Accuracy: 0.9404255319148936\n",
      "rmse: 0.26896175477549755\n",
      "SMD: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        57\n",
      "           1       0.99      0.95      0.97       391\n",
      "           2       0.63      0.86      0.73        22\n",
      "\n",
      "    accuracy                           0.94       470\n",
      "   macro avg       0.81      0.91      0.86       470\n",
      "weighted avg       0.95      0.94      0.94       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"QWK: {cohen_kappa_score(qw_scD_1['prediction'],qw_scD_1['tlabel'],weights='quadratic')}\")\n",
    "print(f\"Accuracy: {accuracy_score(qw_scD_1['prediction'],qw_scD_1['tlabel'])}\")\n",
    "print(f\"rmse: {root_mean_squared_error(qw_scD_1['prediction'],qw_scD_1['tlabel'])}\")\n",
    "print(f\"SMD: {SMD(prediction=qw_scD_1['prediction'],truevalues=qw_scD_1['tlabel'])}\")\n",
    "print(classification_report(qw_scD_1['prediction'],qw_scD_1['tlabel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b1e0f4-7f74-4db7-956f-3e150e4587f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92        57\n",
      "           1       0.97      0.97      0.97       391\n",
      "           2       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.95       470\n",
      "   macro avg       0.90      0.83      0.85       470\n",
      "weighted avg       0.95      0.95      0.95       470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(qw_scD_1['prediction'],scD_0['mode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced96164-fa58-40ba-a4f0-04cfcc268949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
