{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bfda4f-f6bc-4f80-9093-aa67cba2be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "import random\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f04d245-f65b-490a-966e-10e218b1eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_number(s):\n",
    "    \"\"\"\n",
    "    Extracts the first integer from a string, ignoring decimals.\n",
    "\n",
    "    Args:\n",
    "        s: The input string.\n",
    "\n",
    "    Returns:\n",
    "        The first integer found in the string, or None if no integer is found.\n",
    "    \"\"\"\n",
    "    match = re.search(r'\\d+', s)  # Matches only integers\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "## Find modes ###\n",
    "def find_mode(data):\n",
    "    \"\"\"\n",
    "    Finds the mode(s) of a list or pandas Series.\n",
    "    \n",
    "    Args:\n",
    "        data: A list or pandas Series of values.\n",
    "    \n",
    "    Returns:\n",
    "        A single mode if there are multiple modes;\n",
    "        otherwise returns the mode(s) of the input data.\n",
    "        Returns an empty list if the input is empty.\n",
    "    \"\"\"\n",
    "    counts = Counter(data)\n",
    "    max_count = max(counts.values())\n",
    "    modes = [key for key, value in counts.items() if value == max_count]\n",
    "    \n",
    "    # If there are multiple modes, choose one randomly\n",
    "    if len(modes) > 1:\n",
    "        return random.choice(modes)\n",
    "    \n",
    "    return modes[0]\n",
    "\n",
    "def SMD(truevalues,prediction):\n",
    "    mt=truevalues.mean()\n",
    "    mp=prediction.mean()\n",
    "    stdt=truevalues.var()\n",
    "    stdp=prediction.var()\n",
    "    z= (mt-mp)/math.sqrt((stdt+stdt)/2)\n",
    "\n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17aa5d03-e983-46e9-aacf-bf04b8939656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingf\\AppData\\Local\\Temp\\ipykernel_73272\\2337204910.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  resp.replace({'Final': {'0b': 0}},inplace=True)\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/'\n",
    "role = \"You are a helpful rater in science education. You should rate students' responses based on the scoring guide and only return the scores.\\n\"\n",
    "\n",
    "item='VR2'\n",
    "scoring_prompt = pd.read_csv(path+'scoring prompts.csv')\n",
    "scoring_prompt = scoring_prompt.loc[scoring_prompt.Item == item,'Prompt'].values[0]\n",
    "resp = pd.read_excel(path+'All Graded Data from LPS3 2022_ Undergraduates.xlsx',sheet_name=item)\n",
    "resp.replace({'Final': {'0a': 0}},inplace=True)\n",
    "resp.replace({'Final': {'0b': 0}},inplace=True)\n",
    "#resp['Final']=resp['Final'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b69ceff-7341-41b2-be7c-79c81a45d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"Input your own key\")\n",
    "gm_model = genai.GenerativeModel(model_name=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1c82bc-02ca-4315-8933-d67ef1c11600",
   "metadata": {},
   "outputs": [],
   "source": [
    "temprs = [0,1]\n",
    "nrep=5\n",
    "\n",
    "for tempr in temprs:\n",
    "    scP = []\n",
    "    for index, row in resp.iterrows():\n",
    "    #print(index)\n",
    "        scoring_prompt_resp = scoring_prompt+'\\n'+'RESPONSE:'+str(row[item])+'. ->'\n",
    "        scL=[]\n",
    "        for rp in range(nrep):\n",
    "        \n",
    "            gm_scores = gm_model.generate_content(\n",
    "                        generation_config={\"temperature\": tempr},\n",
    "                        contents=role+'\\n'+scoring_prompt_resp,\n",
    "            )\n",
    "            scL.append(gm_scores.text)\n",
    "\n",
    "        scP.append(scL)\n",
    "\n",
    "    gm_scD = pd.DataFrame(scP,columns=['output_'+str(i )for i in range(nrep)])\n",
    "\n",
    "    gm_scD = pd.concat([gm_scD,gm_scD.apply(lambda col: [extract_first_number(i) for i in col]).\\\n",
    "    rename(columns=dict(zip(['output_'+str(i )for i in range(nrep)],['score_'+str(i )for i in range(nrep)])))], axis=1)\n",
    "\n",
    "    gm_scD['mode'] = gm_scD.iloc[:,nrep:(2*nrep)].apply(find_mode,axis=1)\n",
    "\n",
    "    gm_scD.to_csv(path+'results/'+item+'_gemini_tempr'+str(tempr)+'.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ff13038-d5cf-4131-aced-459a92980885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK: 0.7941068320545192\n",
      "Accuracy: 0.788546255506608\n",
      "rmse: 0.4944627307193987\n",
      "SMD: -0.07571254023554079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77        55\n",
      "           1       0.64      0.60      0.62       109\n",
      "           2       0.88      0.87      0.87       272\n",
      "           3       0.62      0.44      0.52        18\n",
      "\n",
      "    accuracy                           0.79       454\n",
      "   macro avg       0.71      0.70      0.69       454\n",
      "weighted avg       0.79      0.79      0.79       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"QWK: {cohen_kappa_score(gm_scD['mode'],resp.Final,weights='quadratic')}\")\n",
    "print(f\"Accuracy: {accuracy_score(gm_scD['mode'],resp.Final)}\")\n",
    "print(f\"rmse: {root_mean_squared_error(gm_scD['mode'],resp.Final)}\")\n",
    "print(f\"SMD: {SMD(prediction=gm_scD['mode'],truevalues=resp.Final)}\")\n",
    "print(classification_report(gm_scD['mode'],resp.Final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5416dd-e288-4af1-8fe8-138ea914c14c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
